{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from heapq import heappush, heappop\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "from numpy import linalg as np_la\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "data=pd.read_csv('E:/SEMESTER 6/ML-CS60050/Assgnment/Third/AllBooks_baseline_DTM_Labelled.csv') #importing the data\n",
    "#n=len(data.axes[0]) #to find number of rows in each attribute\n",
    "\n",
    "#data.drop([13], inplace = True) # removing \"Buddhism_Ch14\" from Dataframe\n",
    "data=data.drop([13], axis=0)\n",
    "\n",
    "data.reset_index(drop=True, inplace=True) # to adjust indices accordingly\n",
    "\n",
    "data[\"Unnamed: 0\"]=data[\"Unnamed: 0\"].str.replace(r'_Ch', '') # to remove \"_Ch\" \n",
    "data[\"Unnamed: 0\"] = data[\"Unnamed: 0\"].str.replace('\\d+', '') # to remove number after book name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# H(Y) - Entropy of class labels\n",
    "def Entropy_of_class_labels(classes,data):\n",
    "    \n",
    "    HY=0\n",
    "    for i in range(len(classes)):\n",
    "        if(len(classes[i])!=0):\n",
    "            p=len(classes[i])/len(data)\n",
    "            HY=HY+(p*np.log2(p))\n",
    "\n",
    "    HY=-HY\n",
    "    return HY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H(C) - Entropy of cluster labels\n",
    "def Entropy_of_cluster_labels(clusters,data):\n",
    "    \n",
    "    H_C=0\n",
    "    for i in range(len(clusters)):\n",
    "        if(len(clusters[i])!=0):\n",
    "            p=len(clusters[i])/len(data)\n",
    "            H_C=H_C+(p*np.log2(p))\n",
    "\n",
    "    H_C=-H_C\n",
    "    return H_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of H(Y|C)=conditional entropy of class labels for clustering C\n",
    "\n",
    "def Conditional_Entropy(clusters,classes):\n",
    "    #start\n",
    "    H_Y_C=0\n",
    "\n",
    "    for i in range(len(clusters)):\n",
    "        count=0\n",
    "        for j in range(len(clusters[i])):\n",
    "            if(clusters[i][j] in classes[i]):\n",
    "                count=count+1\n",
    "        if(count!=0):\n",
    "            p=count/len(clusters[i])\n",
    "            H_Y_C=H_Y_C+p*np.log2(p)\n",
    "\n",
    "        H_Y_C=H_Y_C/len(clusters)\n",
    "\n",
    "    H_Y_C=-H_Y_C\n",
    "    return H_Y_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main code is here\n",
    "data_labels=np.array(data['Unnamed: 0'])   \n",
    "\n",
    "temp=0;\n",
    "for item in data['Unnamed: 0']:\n",
    "    data_labels[temp]=item\n",
    "    temp=temp+1\n",
    "# class labels for 'Unnamed: 0' defined below\n",
    "class_labels=['Buddhism','TaoTeChing','Upanishad','YogaSutra','BookOfProverb', 'BookOfEcclesiastes', 'BookOfEccleasiasticus','BookOfWisdom']\n",
    "for i in range(len(data_labels)):\n",
    "    for j in range(len(class_labels)):\n",
    "        #print(\"data_labels:\",data_labels)\n",
    "        #print(\"class_labels\",class_labels)\n",
    "        if(data_labels[i]==class_labels[j]):\n",
    "            data_labels[i]=j\n",
    "        \n",
    "#print(data_labels)\n",
    "data=data.drop(['Unnamed: 0'], axis=1) #replace the class labels with the new one (data_labels)\n",
    "data.insert(0, 'Unnamed: 0', data_labels)\n",
    "\n",
    "\n",
    "classes=[[],[],[],[],[],[],[],[]]     # stores document number in each class\n",
    "document_labels=np.array(data['Unnamed: 0'])\n",
    "\n",
    "\n",
    "for i in range(len(document_labels)):\n",
    "        classes[document_labels[i]].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI score of agglomerative.txt :  1.8461794521809038\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for \"agglomerative.txt\"\n",
    "\n",
    "\n",
    "file = open(\"E:/SEMESTER 6/ML-CS60050/Assgnment/Third/agglomerative.txt\",\"r\")\n",
    "clusters=[[],[],[],[],[],[],[],[]]\n",
    "index=0\n",
    "\n",
    "for line in file:\n",
    "  \n",
    "    #Let's split the line into an array called \"fields\" using the \",\" as a separator:\n",
    "    fields = line.split(\",\")\n",
    "    \n",
    "    for i in range(len(fields)):\n",
    "        clusters[index].append(fields[i])\n",
    "        \n",
    "    index=index+1\n",
    "    \n",
    "file.close()\n",
    "\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    if(len(clusters[i])!=0):\n",
    "        item=clusters[i][-1]\n",
    "        clusters[i][-1]=item[0:len(item)-1]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "## H(Y) - Entropy of class labels\n",
    "\n",
    "HY=Entropy_of_class_labels(classes,data)\n",
    "\n",
    "\n",
    "## H(C) - Entropy of cluster labels\n",
    "\n",
    "HC=Entropy_of_cluster_labels(clusters,data)\n",
    "\n",
    "\n",
    "# Calculation of H(Y|C)\n",
    "\n",
    "HYC=Conditional_Entropy(clusters,classes)\n",
    "\n",
    "\n",
    "IYC=HY-HYC\n",
    "\n",
    "\n",
    "## NMI(Normalized Mutual Information) = (2*I(Y;C))/(H(Y)+H(C))\n",
    "\n",
    "NMI=(2*IYC)/(HY+HC)\n",
    "\n",
    "print(\"NMI score of agglomerative.txt : \",NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI score of kmeans.txt :  0.9187470250416958\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for \"kmeans.txt\"\n",
    "\n",
    "file = open(\"E:/SEMESTER 6/ML-CS60050/Assgnment/Third/kmeans.txt\",\"r\")\n",
    "clusters=[[],[],[],[],[],[],[],[]]\n",
    "index=0\n",
    "\n",
    "for line in file:\n",
    "  \n",
    "    #Let's split the line into an array called \"fields\" using the \",\" as a separator:\n",
    "    fields = line.split(\",\")\n",
    "    \n",
    "    for i in range(len(fields)):\n",
    "        clusters[index].append(fields[i])\n",
    "        \n",
    "    index=index+1\n",
    "    \n",
    "file.close()\n",
    "\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    if(len(clusters[i])!=0):\n",
    "        item=clusters[i][-1]\n",
    "        clusters[i][-1]=item[0:len(item)-1]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "## H(Y) - Entropy of class labels\n",
    "\n",
    "HY=Entropy_of_class_labels(classes,data)\n",
    "\n",
    "## H(C) - Entropy of cluster labels\n",
    "\n",
    "HC=Entropy_of_cluster_labels(clusters,data)\n",
    "\n",
    "# Calculation of H(Y|C)\n",
    "\n",
    "HYC=Conditional_Entropy(clusters,classes)\n",
    "\n",
    "\n",
    "IYC=HY-HYC\n",
    "\n",
    "\n",
    "## NMI(Normalized Mutual Information) = (2*I(Y;C))/(H(Y)+H(C))\n",
    "\n",
    "NMI=(2*IYC)/(HY+HC)\n",
    "\n",
    "print(\"NMI score of kmeans.txt : \",NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI score of kmeans_reduced.txt :  1.0304797047978522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for \"kmeans.txt\"\n",
    "\n",
    "file = open(\"E:/SEMESTER 6/ML-CS60050/Assgnment/Third/kmeans_reduced.txt\",\"r\")\n",
    "clusters=[[],[],[],[],[],[],[],[]]\n",
    "index=0\n",
    "\n",
    "for line in file:\n",
    "  \n",
    "    #Let's split the line into an array called \"fields\" using the \",\" as a separator:\n",
    "    fields = line.split(\",\")\n",
    "    \n",
    "    for i in range(len(fields)):\n",
    "        clusters[index].append(fields[i])\n",
    "        \n",
    "    index=index+1\n",
    "    \n",
    "file.close()\n",
    "\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    if(len(clusters[i])!=0):\n",
    "        item=clusters[i][-1]\n",
    "        clusters[i][-1]=item[0:len(item)-1]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "## H(Y) - Entropy of class labels\n",
    "\n",
    "HY=Entropy_of_class_labels(classes,data)\n",
    "\n",
    "## H(C) - Entropy of cluster labels\n",
    "\n",
    "HC=Entropy_of_cluster_labels(clusters,data)\n",
    "\n",
    "# Calculation of H(Y|C)\n",
    "\n",
    "HYC=Conditional_Entropy(clusters,classes)\n",
    "\n",
    "\n",
    "IYC=HY-HYC\n",
    "\n",
    "\n",
    "## NMI(Normalized Mutual Information) = (2*I(Y;C))/(H(Y)+H(C))\n",
    "\n",
    "NMI=(2*IYC)/(HY+HC)\n",
    "\n",
    "print(\"NMI score of kmeans_reduced.txt : \",NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI score of agglomerative_reduced.txt :  1.8461794521809038\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for \"agglomerative_reduced.txt\"\n",
    "\n",
    "file = open(\"E:/SEMESTER 6/ML-CS60050/Assgnment/Third/agglomerative_reduced.txt\",\"r\")\n",
    "clusters=[[],[],[],[],[],[],[],[]]\n",
    "index=0\n",
    "\n",
    "for line in file:\n",
    "  \n",
    "    #Let's split the line into an array called \"fields\" using the \",\" as a separator:\n",
    "    fields = line.split(\",\")\n",
    "    \n",
    "    for i in range(len(fields)):\n",
    "        clusters[index].append(fields[i])\n",
    "        \n",
    "    index=index+1\n",
    "    \n",
    "file.close()\n",
    "\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    if(len(clusters[i])!=0):\n",
    "        item=clusters[i][-1]\n",
    "        clusters[i][-1]=item[0:len(item)-1]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "## H(Y) - Entropy of class labels\n",
    "\n",
    "HY=Entropy_of_class_labels(classes,data)\n",
    "\n",
    "\n",
    "## H(C) - Entropy of cluster labels\n",
    "\n",
    "HC=Entropy_of_cluster_labels(clusters,data)\n",
    "\n",
    "\n",
    "# for H(Y|C)\n",
    "\n",
    "HYC=Conditional_Entropy(clusters,classes)\n",
    "\n",
    "\n",
    "IYC=HY-HYC\n",
    "\n",
    "\n",
    "NMI=(2*IYC)/(HY+HC)\n",
    "\n",
    "print(\"NMI score of agglomerative_reduced.txt : \",NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
