{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_A2_q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2DLzv-gfPrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUZR3ORciKxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('winequality-red.csv', sep=';') #importing the data\n",
        "for i in range(11): # except quality feature every column included here\n",
        "   x=data.iloc[:,i]\n",
        "   x_minmax_scaled=(x-x.min())/(x.max()-x.min()) # Normalization using min-max scaling\n",
        "   data.iloc[:,i]=x_minmax_scaled\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GptufKWWiOrH",
        "colab_type": "code",
        "outputId": "cc36e62a-c343-4d99-aabd-727ecdff65ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        }
      },
      "source": [
        "#n=len(data.axes[0]) #to find number of rows in each attribute\n",
        "#print('Number of rows are: ', n)\n",
        "n=1599\n",
        "for i in range(n):\n",
        "  x=data.iloc[i,11]\n",
        "  if(x<=6) :\n",
        "    x=0\n",
        "  else :\n",
        "    x=1\n",
        "  data.iloc[i,11]=x   \n",
        "  \n",
        "  \n",
        "\n",
        "print(data.iloc[0:50,:])\n"
      ],
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    fixed acidity  volatile acidity  citric acid  ...  sulphates   alcohol  quality\n",
            "0        0.247788          0.397260         0.00  ...   0.137725  0.153846        0\n",
            "1        0.283186          0.520548         0.00  ...   0.209581  0.215385        0\n",
            "2        0.283186          0.438356         0.04  ...   0.191617  0.215385        0\n",
            "3        0.584071          0.109589         0.56  ...   0.149701  0.215385        0\n",
            "4        0.247788          0.397260         0.00  ...   0.137725  0.153846        0\n",
            "5        0.247788          0.369863         0.00  ...   0.137725  0.153846        0\n",
            "6        0.292035          0.328767         0.06  ...   0.077844  0.153846        0\n",
            "7        0.238938          0.363014         0.00  ...   0.083832  0.246154        1\n",
            "8        0.283186          0.315068         0.02  ...   0.143713  0.169231        1\n",
            "9        0.256637          0.260274         0.36  ...   0.281437  0.323077        0\n",
            "10       0.185841          0.315068         0.08  ...   0.125749  0.123077        0\n",
            "11       0.256637          0.260274         0.36  ...   0.281437  0.323077        0\n",
            "12       0.088496          0.339041         0.00  ...   0.113772  0.230769        0\n",
            "13       0.283186          0.335616         0.29  ...   0.736527  0.107692        0\n",
            "14       0.380531          0.342466         0.18  ...   0.329341  0.123077        0\n",
            "15       0.380531          0.342466         0.19  ...   0.359281  0.123077        0\n",
            "16       0.345133          0.109589         0.56  ...   0.251497  0.323077        1\n",
            "17       0.309735          0.301370         0.28  ...   0.568862  0.138462        0\n",
            "18       0.247788          0.321918         0.08  ...   0.101796  0.092308        0\n",
            "19       0.292035          0.136986         0.51  ...   0.449102  0.123077        0\n",
            "20       0.380531          0.068493         0.48  ...   0.119760  0.153846        0\n",
            "21       0.265487          0.184932         0.31  ...   0.191617  0.200000        0\n",
            "22       0.292035          0.212329         0.21  ...   0.347305  0.169231        0\n",
            "23       0.345133          0.253425         0.11  ...   0.119760  0.153846        0\n",
            "24       0.203540          0.191781         0.14  ...   0.179641  0.200000        0\n",
            "25       0.150442          0.184932         0.16  ...   0.137725  0.138462        0\n",
            "26       0.265487          0.198630         0.24  ...   0.155689  0.169231        0\n",
            "27       0.292035          0.212329         0.21  ...   0.347305  0.169231        0\n",
            "28       0.221239          0.404110         0.00  ...   0.131737  0.153846        0\n",
            "29       0.283186          0.359589         0.00  ...   0.155689  0.215385        0\n",
            "30       0.185841          0.380137         0.07  ...   0.125749  0.261538        0\n",
            "31       0.203540          0.386986         0.00  ...   0.143713  0.338462        0\n",
            "32       0.327434          0.366438         0.12  ...   0.197605  0.215385        0\n",
            "33       0.203540          0.332192         0.12  ...   0.113772  0.153846        0\n",
            "34       0.053097          0.136986         0.25  ...   0.131737  0.123077        0\n",
            "35       0.283186          0.359589         0.00  ...   0.131737  0.184615        0\n",
            "36       0.283186          0.328767         0.14  ...   0.161677  0.369231        0\n",
            "37       0.309735          0.178082         0.28  ...   0.239521  0.200000        1\n",
            "38       0.097345          0.691781         0.09  ...   0.089820  0.215385        0\n",
            "39       0.238938          0.226027         0.36  ...   0.299401  0.323077        0\n",
            "40       0.238938          0.226027         0.36  ...   0.299401  0.323077        0\n",
            "41       0.371681          0.335616         0.30  ...   0.107784  0.138462        0\n",
            "42       0.256637          0.253425         0.20  ...   0.341317  0.323077        0\n",
            "43       0.309735          0.369863         0.22  ...   0.520958  0.292308        0\n",
            "44       0.194690          0.376712         0.02  ...   0.113772  0.169231        0\n",
            "45       0.000000          0.273973         0.15  ...   0.137725  0.723077        0\n",
            "46       0.274336          0.558219         0.43  ...   0.239521  0.123077        0\n",
            "47       0.362832          0.116438         0.52  ...   0.149701  0.169231        0\n",
            "48       0.159292          0.191781         0.23  ...   0.137725  0.123077        0\n",
            "49       0.088496          0.130137         0.37  ...   0.149701  0.123077        0\n",
            "\n",
            "[50 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1XAQw8wKVeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWWDuYlKLSzx",
        "colab_type": "text"
      },
      "source": [
        "# Defining All function here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpByA81hiX_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost_function(X, y, theta): # to compute cost, cost function is defined\n",
        "    m = len(y)\n",
        "    z=(X @ theta) # dot production between input X and params \n",
        "    h_theta=1 / (1 + np.exp(-z)) #defining logistic hypothesis function i.e. sigmoid function\n",
        "    # here '@' is used for dot product or matrix multiplication    \n",
        "    cost = (1/m)*(((-y).T @ np.log(h_theta))-((1-y).T @ np.log(1-h_theta)))\n",
        "    return cost\n",
        "\n",
        "\n",
        "def GD(X, y, params, lr, itr): #to udate parameter gradient descent is defined\n",
        "    m = len(y) # size of sample\n",
        "    J_theta = np.zeros((itr,1)) # recording history of cost function over iteration\n",
        "\n",
        "    for i in range(itr):\n",
        "        z=(X @ params) # dot production between input X and params \n",
        "        h=1 / (1 + np.exp(-z)) #defining logistic hypothesis function i.e. sigmoid function\n",
        "        params = params - (lr/m) * (X.T @ (h - y)) \n",
        "        J_theta[i] = cost_function(X, y, params)\n",
        "\n",
        "    return (J_theta, params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7IxxxpXI080",
        "colab_type": "text"
      },
      "source": [
        "# NOW FOR CALCULATING PARAMS, COST FUNCTION AND PREDICTED VALUE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LdqPHRGJK71",
        "colab_type": "code",
        "outputId": "2395c966-ae87-43b6-a177-aaa3caa28dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# initialisation\n",
        "X=data.iloc[:,0:11]\n",
        "y=data.iloc[:,11]\n",
        "m = len(y)\n",
        "\n",
        "X = np.hstack((np.ones((m,1)),X)) # adding/inserting bias as 1 \n",
        "y = y[:,np.newaxis]\n",
        "n = np.size(X,1)\n",
        "params = np.zeros((n,1))\n",
        "\n",
        "iterations = 1500\n",
        "learning_rate = 0.01\n",
        "# Assigning value to function now\n",
        "cost_function_initial = cost_function(X, y, params) # initial  value of cost function before start of iteration\n",
        "\n",
        "print(\"Initial Cost is: {} \\n\".format(cost_function_initial))\n",
        "\n",
        "(J_theta, params_final) = GD(X, y, params, learning_rate, iterations) # to calculater J_theta over iteration and parameter final updated value\n",
        "\n",
        "print(\" Final Updated value of Parameters are: \\n\", params_final, \"\\n\")\n",
        "\n"
      ],
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Cost is: [[0.69314718]] \n",
            "\n",
            " Final Updated value of Parameters are: \n",
            " [[-0.97950192]\n",
            " [-0.21439513]\n",
            " [-0.43750352]\n",
            " [-0.04074204]\n",
            " [-0.07839054]\n",
            " [-0.1592965 ]\n",
            " [-0.24889738]\n",
            " [-0.21465394]\n",
            " [-0.56623354]\n",
            " [-0.47626792]\n",
            " [-0.08432961]\n",
            " [ 0.03089778]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5bZ0ef0JZZr",
        "colab_type": "code",
        "outputId": "780173a3-d018-4236-b3c6-56867bdda794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# for plotting graph between Cost function and iteration\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(range(iterations),J_theta)\n",
        "plt.title(\"Cost vs iteration\")\n",
        "plt.xlabel(\"Number of Iterations\")\n",
        "plt.ylabel(\"Cost or J_ theta\")\n",
        "plt.show()"
      ],
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZlYjzb1LM7X",
        "colab_type": "code",
        "outputId": "7049a985-66c3-4584-99f7-125f6b384347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# to calculate accuracy\n",
        "z=(X @ params) # dot production between input X and params \n",
        "h=1 / (1 + np.exp(-z)) #defining logistic hypothesis function i.e. sigmoid function\n",
        "y_pred = np.round(h) # using threshold vaue 0.5 we just rounding up it\n",
        "accuracy = float(sum(y_pred == y))/ float(len(y))*100\n",
        "\n",
        "print('Accuracy without scikit learn modal=',accuracy) # Accuracy without any model impletation"
      ],
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy without scikit learn modal= 86.42901813633522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SFDmSUXDVi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXxtpvFpU-yI",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: using scikit learn package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZIoH08XVIMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JRAo5IsVJwI",
        "colab_type": "code",
        "outputId": "a950725a-168d-494b-d294-e687caf2af70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "'''X1=X # taking from above part\n",
        "y1=y # taking value from above part\n",
        "clf = LogisticRegression(random_state=0).fit(X1, y1)\n",
        "y_pred_sklearn= LogisticRegression.predict(X1)'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        " \n",
        "x1 = X\n",
        "y1 = y\n",
        "x_train, x_test, y_train, y_test = train_test_split(x1, y1, test_size=0.33, random_state=1)\n",
        "logmodel = LogisticRegression()\n",
        "logmodel.fit(x_train, y_train)\n",
        " \n",
        "y_pred_sklearn = logmodel.predict(x_test)\n",
        "\n",
        "print('Accuracy from scikit learn model=',accuracy_score(y_test, y_pred_sklearn)*100)"
      ],
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy from scikit learn model= 87.68939393939394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zxkaPvtV9c2",
        "colab_type": "code",
        "outputId": "fc7d281d-3825-420c-f39e-9370736d8ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''accuracy1=clf.score(X, y) * 100\n",
        "print('Accuracy from scikit learn model=',accuracy1)'''"
      ],
      "execution_count": 465,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"accuracy1=clf.score(X, y) * 100\\nprint('Accuracy from scikit learn model=',accuracy1)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 465
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F-8ILHSWCFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igrcth83W42S",
        "colab_type": "text"
      },
      "source": [
        "# Part 3: 3 fold Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BPalEaAXIwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWZM_WACjb48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2=X # taking from above part\n",
        "y2=y # taking value from above part\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X2, y2, random_state=6)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLoXDKa2oARq",
        "colab_type": "code",
        "outputId": "13c773cc-9836-4f46-d0af-51aee714a2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "accuracy_logistic=cross_val_score(logreg, X2, y2, cv=3, scoring='accuracy').mean()\n",
        "print('Mean accuracy of 3 fold cross validation for logistic regression=',accuracy_logistic*100)"
      ],
      "execution_count": 468,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy of 3 fold cross validation for logistic regression= 86.9918699186992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmBi5GpK1h5n",
        "colab_type": "code",
        "outputId": "041476a6-d012-4651-816b-3102cf5c9c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#precision recall for Logistic regresion without sklearn\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "#predicted = [1,2,3,4,5,1,2,1,1,4,5] \n",
        "#y_test = [1,2,3,4,5,1,2,1,1,4,1]\n",
        "\n",
        "precision, recall, fscore, support = score(y1, y_pred) # y_pred is value from logistic regression classifier\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))"
      ],
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: [0.86429018 0.        ]\n",
            "recall: [1. 0.]\n",
            "fscore: [0.92720564 0.        ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqBM1EK12fNz",
        "colab_type": "code",
        "outputId": "b3d4c546-f818-4f67-bd63-6bba6d55f4f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "\n",
        "#precision recall with sklearn classifier\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "\n",
        "precision, recall, fscore, support = score(y_test, y_pred_sklearn) # y_pred is value from logistic regression classifier\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n"
      ],
      "execution_count": 470,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: [0.89065606 0.6       ]\n",
            "recall: [0.97816594 0.21428571]\n",
            "fscore: [0.93236212 0.31578947]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhrS_GZr26Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}